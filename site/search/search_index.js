var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"index.html#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"index.html#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"index.html#katex","title":"katex","text":"<p>$\\frac{1}{2}$</p>"},{"location":"about.html","title":"about","text":""},{"location":"gcp/pubsub.html","title":"pubsub","text":""},{"location":"gcp/pubsub.html#_1","title":"\u7528\u8a9e\u3092\u307e\u3068\u3081\u308b","text":"<p>\u767b\u5834\u4eba\u7269\u306fPublisher, Topic, Subscription, Subscriber</p> <p>\ud83d\udcd5\u00a0\u30c8\u30d4\u30c3\u30af</p> <p>Publisher(\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u9001\u4fe1\u5143)\u30681:1\u3067\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u3082\u306e</p> <p>\ud83d\udcd5\u00a0\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3</p> <p>\u5c4a\u3044\u305f\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u7ba1\u7406\u3001\u30b5\u30d6\u30b9\u30af\u30e9\u30a4\u30d0\u30fc(\u53d7\u4fe1\u8005)\u306b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u9001\u308b</p>"},{"location":"gcp/pubsub.html#_2","title":"\u30ed\u30fc\u30ab\u30eb\u3067\u306e\u52d5\u4f5c\u78ba\u8a8d\u65b9\u6cd5\u7b49","text":"<p>pull\u578b\u3068push\u578b\u304c\u5b58\u5728\u3057\u3066\u304a\u308a\u3001pull\u578b\u306f\u53d7\u4fe1\u8005\u304c\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u306b\u3044\u304f\u3001push\u578b\u306f\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u304c\u30c7\u30fc\u30bf\u3092\u5c4a\u3051\u308b\u30a4\u30e1\u30fc\u30b8</p> <p>\u30ed\u30fc\u30ab\u30eb\u3067\u78ba\u304b\u3081\u308b</p> <pre><code>gcloud pubsub topics create tosa-sample\ngcloud pubsub subscriptions create tosa-sample-sub --topic=tosa-sample\ngcloud pubsub topics publish tosa-sample --message=\"hello\"\ngcloud pubsub subscriptions pull tosa-sample-sub --auto-ack\n</code></pre> <p>\u4e0a\u8a18\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001Google Cloud Platform\uff08GCP\uff09\u306ePub/Sub\uff08\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5/\u30b5\u30d6\u30b9\u30af\u30e9\u30a4\u30d6\uff09\u30b5\u30fc\u30d3\u30b9\u3092\u4f7f\u7528\u3057\u3066\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u30f3\u30b0\u30b7\u30b9\u30c6\u30e0\u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3057\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u9001\u53d7\u4fe1\u3059\u308b\u305f\u3081\u306e\u3082\u306e\u3067\u3059\u3002\u4ee5\u4e0b\u3001\u305d\u308c\u305e\u308c\u306e\u30b3\u30de\u30f3\u30c9\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002</p> <ol> <li><code>gcloud pubsub topics create tosa-sample</code></li> </ol> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001Pub/Sub\u30c8\u30d4\u30c3\u30af\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u30c8\u30d4\u30c3\u30af\u306f\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u9001\u4fe1\u5143\u3067\u3042\u308a\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u9001\u4fe1\u5148\u3092\u8b58\u5225\u3057\u307e\u3059\u3002\u3053\u306e\u30b3\u30de\u30f3\u30c9\u3067\u306f\u3001\"tosa-sample\"\u3068\u3044\u3046\u540d\u524d\u306e\u30c8\u30d4\u30c3\u30af\u3092\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059\u3002</p> <ol> <li><code>gcloud pubsub subscriptions create tosa-sample-sub --topic=tosa-sample</code></li> </ol> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u30c8\u30d4\u30c3\u30af\u306b\u5bfe\u3059\u308b\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\uff08\u8cfc\u8aad\uff09\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u306f\u3001\u30c8\u30d4\u30c3\u30af\u306b\u5bfe\u3057\u3066\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u4fe1\u3059\u308b\u5bfe\u8c61\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u306f\u3001\"tosa-sample-sub\"\u3068\u3044\u3046\u540d\u524d\u306e\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u3092\u3001\u5148\u307b\u3069\u4f5c\u6210\u3057\u305f\"tosa-sample\"\u30c8\u30d4\u30c3\u30af\u306b\u5bfe\u3057\u3066\u4f5c\u6210\u3057\u3066\u3044\u307e\u3059\u3002</p> <ol> <li><code>gcloud pubsub topics publish tosa-sample --message=\"hello\"</code></li> </ol> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u6307\u5b9a\u3057\u305f\u30c8\u30d4\u30c3\u30af\uff08\"tosa-sample\"\uff09\u306b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u516c\u958b\uff08\u9001\u4fe1\uff09\u3057\u307e\u3059\u3002\u30e1\u30c3\u30bb\u30fc\u30b8\u306e\u5185\u5bb9\u306f\u3001\"--message\"\u30d5\u30e9\u30b0\u3067\u6307\u5b9a\u3055\u308c\u3066\u304a\u308a\u3001\u3053\u3053\u3067\u306f\"hello\"\u3068\u3044\u3046\u6587\u5b57\u5217\u3092\u542b\u3093\u3067\u3044\u307e\u3059\u3002</p> <ol> <li><code>gcloud pubsub subscriptions pull tosa-sample-sub --auto-ack</code></li> </ol> <p>\u3053\u306e\u30b3\u30de\u30f3\u30c9\u306f\u3001\u6307\u5b9a\u3057\u305f\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\uff08\"tosa-sample-sub\"\uff09\u304b\u3089\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d6\u5f97\uff08\u30d7\u30eb\uff09\u3057\u307e\u3059\u3002\"--auto-ack\"\u30d5\u30e9\u30b0\u304c\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u4fe1\u3057\u305f\u5f8c\u3001\u660e\u793a\u7684\u306a\u78ba\u8a8d\u3092\u884c\u308f\u305a\u306b\u81ea\u52d5\u7684\u306b\u53d7\u4fe1\u304c\u78ba\u8a8d\u3055\u308c\u307e\u3059\uff08ACK\u304c\u9001\u4fe1\u3055\u308c\u307e\u3059\uff09\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u4e00\u5ea6\u3057\u304b\u51e6\u7406\u3055\u308c\u306a\u3044\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002</p> <p>\u3053\u308c\u3089\u306e\u30b3\u30de\u30f3\u30c9\u3092\u9806\u306b\u5b9f\u884c\u3059\u308b\u3068\u3001\"tosa-sample\"\u30c8\u30d4\u30c3\u30af\u306b\"hello\"\u3068\u3044\u3046\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u9001\u4fe1\u3055\u308c\u3001\"tosa-sample-sub\"\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u304c\u305d\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u4fe1\u3057\u3066\u51e6\u7406\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002\u305f\u3060\u3057\u3001\u5b9f\u969b\u306b\u306f\u3001\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u53d7\u4fe1\u3057\u305f\u5f8c\u306e\u51e6\u7406\u3084\u3001\u30b5\u30d6\u30b9\u30af\u30ea\u30d7\u30b7\u30e7\u30f3\u306e\u8a2d\u5b9a\u306a\u3069\u3001\u3055\u307e\u3056\u307e\u306a\u5074\u9762\u304c\u5b58\u5728\u3057\u307e\u3059\u3002</p>"},{"location":"these/machineLearningOfHighDimensionalDataOnANoisyQuantumProcessor.html","title":"Machine learning of high dimensional data on a noisy quantum processor","text":"<pre><code>gpt\u306b\u3088\u308b\u6a5f\u68b0\u7ffb\u8a33\u3067\u3059\u548c\u8a33\u5f8c\u306e\u6587\u7ae0\u306f\u6b63\u78ba\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n</code></pre> <p>[1]  \u672c\u6587: </p> <p>\\section{Introduction}</p> <p>Quantum kernel methods (QKM) \\cite{Havlicek2019,PhysRevLett.122.040504} provide techniques for utilizing a quantum co-processor in a machine learning setting. These methods were recently proven to provide a speedup over classical methods for certain specific input data classes \\cite{liu2020rigorous}. They have also been used to quantify the computational power of data in quantum machine learning algorithms and drive the conditions under which quantum models will be capable of outperforming classical ones \\cite{huang2020power}.  Prior experimental work \\cite{kusumoto2019experimental,bartkiewicz2020experimental,Havlicek2019} has focused on artificial or heavily pre-processed data, hardware implementations involving very few qubits, or circuit connectivity unsuitable  \u548c\u8a33:  \\section{\u5e8f\u8ad6}</p> <p>\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\uff08QKM\uff09\\cite{Havlicek2019,PhysRevLett.122.040504}\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u8a2d\u5b9a\u306b\u304a\u3044\u3066\u91cf\u5b50\u30b3\u30d7\u30ed\u30bb\u30c3\u30b5\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u6280\u8853\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002 \u3053\u308c\u3089\u306e\u65b9\u6cd5\u306f\u3001\u6700\u8fd1\u306e\u7814\u7a76\u306b\u3088\u308a\u3001\u7279\u5b9a\u306e\u5165\u529b\u30c7\u30fc\u30bf\u30af\u30e9\u30b9\u306b\u304a\u3044\u3066\u53e4\u5178\u7684\u306a\u65b9\u6cd5\u306b\u6bd4\u3079\u3066\u9ad8\u901f\u5316\u3092\u5b9f\u73fe\u3059\u308b\u3053\u3068\u304c\u8a3c\u660e\u3055\u308c\u3066\u3044\u307e\u3059\\cite{liu2020rigorous}\u3002 \u307e\u305f\u3001\u3053\u308c\u3089\u306e\u65b9\u6cd5\u306f\u3001\u91cf\u5b50\u30de\u30b7\u30f3\u30e9\u30fc\u30cb\u30f3\u30b0\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u304a\u3051\u308b\u30c7\u30fc\u30bf\u306e\u8a08\u7b97\u80fd\u529b\u3092\u5b9a\u91cf\u5316\u3057\u3001\u91cf\u5b50\u30e2\u30c7\u30eb\u304c\u53e4\u5178\u7684\u306a\u30e2\u30c7\u30eb\u3092\u51cc\u99d5\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u306a\u6761\u4ef6\u3092\u793a\u3059\u305f\u3081\u306b\u4f7f\u7528\u3055\u308c\u3066\u3044\u307e\u3059\\cite{huang2020power}\u3002 \u5f93\u6765\u306e\u5b9f\u9a13\\cite{kusumoto2019experimental,bartkiewicz2020experimental,Havlicek2019}\u3067\u306f\u3001\u4eba\u5de5\u7684\u306a\u30c7\u30fc\u30bf\u3084\u53b3\u5bc6\u306b\u524d\u51e6\u7406\u3055\u308c\u305f\u30c7\u30fc\u30bf\u3001\u975e\u5e38\u306b\u5c11\u6570\u306e\u30ad\u30e5\u30d3\u30c3\u30c8\u3092\u4f7f\u7528\u3057\u305f\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u5b9f\u88c5\u3001\u56de\u8def\u306e\u63a5\u7d9a\u6027\u306a\u3069\u304c\u9069\u5207\u3067\u306a\u3044\u3082\u306e\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u304d\u307e\u3057\u305f\u3002</p> <p>[2]  \u672c\u6587:   for NISQ \\cite{Preskill2018quantumcomputingin} processors; recent experimental results show potential for many-qubit applications of QKM to high energy physics \\cite{wu2020application}.</p> <p>In this work, we extend the method of machine learning based on quantum kernel methods up to 17 hardware qubits requiring only nearest-neighbor connectivity. We use this circuit structure to prepare a kernel matrix for a classical support vector machine to learn patterns in 67-dimensional supernova data for which competitive classical classifiers fail to achieve 100\\% accuracy. To extract useful information from a processor without quantum error correction (QEC), we implement error mitigation techniques specific to the QKM algorithm and experimentally demonstrate the algorithm's robustness to some of the   \u548c\u8a33:  \u6700\u8fd1\u306e\u5b9f\u9a13\u7d50\u679c\u304b\u3089\u3001NISQ\uff08Noisy Intermediate-Scale Quantum\uff09\u30d7\u30ed\u30bb\u30c3\u30b5\u306b\u304a\u3044\u3066\u3001QKM\uff08Quantum Kernel Method\uff09\u3092\u7528\u3044\u305f\u591a\u30ad\u30e5\u30fc\u30d3\u30c3\u30c8\u306e\u9ad8\u30a8\u30cd\u30eb\u30ae\u30fc\u7269\u7406\u5b66\u3078\u306e\u5fdc\u7528\u306e\u53ef\u80fd\u6027\u304c\u793a\u3055\u308c\u3066\u3044\u308b\\cite{wu2020application}\u3002\u672c\u7814\u7a76\u3067\u306f\u3001\u6700\u5bc4\u308a\u63a5\u7d9a\u306e\u307f\u3092\u5fc5\u8981\u3068\u3059\u308b17\u500b\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30ad\u30e5\u30fc\u30d3\u30c3\u30c8\u306b\u57fa\u3065\u3044\u305f\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u3092\u6a5f\u68b0\u5b66\u7fd2\u306e\u624b\u6cd5\u3068\u3057\u3066\u62e1\u5f35\u3059\u308b\u3002\u6211\u3005\u306f\u3001\u3053\u306e\u56de\u8def\u69cb\u9020\u3092\u7528\u3044\u3066\u3001\u7af6\u5408\u3059\u308b\u53e4\u5178\u7684\u306a\u5206\u985e\u5668\u304c100\uff05\u306e\u6b63\u89e3\u7387\u3092\u9054\u6210\u3067\u304d\u306a\u304467\u6b21\u5143\u306e\u8d85\u65b0\u661f\u30c7\u30fc\u30bf\u306e\u30d1\u30bf\u30fc\u30f3\u3092\u5b66\u7fd2\u3059\u308b\u305f\u3081\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u5411\u3051\u306e\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u306e\u6e96\u5099\u3092\u884c\u3046\u3002\u91cf\u5b50\u8aa4\u308a\u8a02\u6b63\uff08QEC\uff09\u3092\u6301\u305f\u306a\u3044\u30d7\u30ed\u30bb\u30c3\u30b5\u304b\u3089\u6709\u7528\u306a\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u305f\u3081\u306b\u3001QKM\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u7279\u5316\u3057\u305f\u8aa4\u308a\u8efd\u6e1b\u6280\u8853\u3092\u5b9f\u88c5\u3057\u3001\u305d\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u30ed\u30d0\u30b9\u30c8\u6027\u3092\u5b9f\u9a13\u7684\u306b\u30c7\u30e2\u30f3\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3059\u308b\u3002</p> <p>[3]  \u672c\u6587:  device noise. Additionally, we justify our circuit design based on its ability to produce large kernel magnitudes that can be sampled to high statistical certainty with relatively short experimental runs.</p> <p>We implement this algorithm on the Google Sycamore processor which we accessed through Google's Quantum Computing Service. This machine is similar to the quantum supremacy demonstration Sycamore chip \\cite{Arute2019}, but with only 23 qubits active. We achieve competitive results on a nontrivial classical dataset, and find intriguing classifier robustness in the face of moderate circuit fidelity. Our results motivate further theoretical work on noisy kernel methods and on techniques for operating on real, high-dimensional data without additional classical pre-processing or dimensionality  \u548c\u8a33:  \u88c5\u7f6e\u306e\u30ce\u30a4\u30ba\u306b\u3088\u308b\u5f71\u97ff\u3092\u6700\u5c0f\u9650\u306b\u6291\u3048\u308b\u305f\u3081\u306b\u3001\u56de\u8def\u8a2d\u8a08\u3092\u6b63\u5f53\u5316\u3057\u307e\u3059\u3002\u3055\u3089\u306b\u3001\u6bd4\u8f03\u7684\u77ed\u3044\u5b9f\u9a13\u6642\u9593\u3067\u9ad8\u3044\u7d71\u8a08\u7684\u78ba\u7387\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u308b\u3088\u3046\u306a\u5927\u304d\u306a\u30ab\u30fc\u30cd\u30eb\u306e\u5927\u304d\u3055\u3092\u751f\u6210\u3059\u308b\u80fd\u529b\u306b\u57fa\u3065\u3044\u3066\u3001\u56de\u8def\u8a2d\u8a08\u3092\u6b63\u5f53\u5316\u3057\u307e\u3059\u3002</p> <p>\u79c1\u305f\u3061\u306f\u3001Google\u306e\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30b5\u30fc\u30d3\u30b9\u3092\u4ecb\u3057\u3066\u30a2\u30af\u30bb\u30b9\u3057\u305fGoogle\u306eSycamore\u30d7\u30ed\u30bb\u30c3\u30b5\u4e0a\u3067\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u306e\u30de\u30b7\u30f3\u306f\u3001\u91cf\u5b50\u512a\u4f4d\u30c7\u30e2\u30f3\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u306eSycamore\u30c1\u30c3\u30d7\\cite{Arute2019}\u306b\u4f3c\u3066\u3044\u307e\u3059\u304c\u3001\u30a2\u30af\u30c6\u30a3\u30d6\u306a\u91cf\u5b50\u30d3\u30c3\u30c8\u306f23\u500b\u306e\u307f\u3067\u3059\u3002\u79c1\u305f\u3061\u306f\u3001\u975e\u81ea\u660e\u306a\u30af\u30e9\u30b7\u30ab\u30eb\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u7af6\u4e89\u529b\u306e\u3042\u308b\u7d50\u679c\u3092\u9054\u6210\u3057\u3001\u4e2d\u7a0b\u5ea6\u306e\u56de\u8def\u306e\u6b63\u78ba\u3055\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u8208\u5473\u6df1\u3044\u5206\u985e\u5668\u306e\u9811\u5065\u6027\u3092\u898b\u3064\u3051\u307e\u3059\u3002\u79c1\u305f\u3061\u306e\u7d50\u679c\u306f\u3001\u30ce\u30a4\u30ba\u306e\u3042\u308b\u30ab\u30fc\u30cd\u30eb\u6cd5\u3068\u73fe\u5b9f\u306e\u9ad8\u6b21\u5143\u30c7\u30fc\u30bf\u4e0a\u3067\u306e\u8ffd\u52a0\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u524d\u51e6\u7406\u3084\u6b21\u5143\u524a\u6e1b\u306a\u3057\u306b\u64cd\u4f5c\u3059\u308b\u305f\u3081\u306e\u6280\u8853\u306b\u95a2\u3059\u308b\u3055\u3089\u306a\u308b\u7406\u8ad6\u7684\u7814\u7a76\u3092\u4fc3\u3059\u3082\u306e\u3067\u3059\u3002</p> <p>\u88c5\u7f6e\u306e\u30ce\u30a4\u30ba\u306b\u3088\u308b\u5f71\u97ff\u3092\u6700\u5c0f\u9650\u306b\u6291\u3048\u308b\u305f\u3081\u306b\u3001\u56de\u8def\u8a2d\u8a08\u3092\u6b63\u5f53\u5316\u3057\u307e\u3059\u3002\u3055\u3089\u306b\u3001\u6bd4\u8f03\u7684\u77ed\u3044\u5b9f\u9a13\u6642\u9593\u3067\u9ad8\u3044\u7d71\u8a08\u7684\u78ba\u7387\u3067\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u308b\u3088\u3046\u306a\u5927\u304d\u306a\u30ab\u30fc\u30cd\u30eb\u306e\u5927\u304d\u3055\u3092\u751f\u6210\u3059\u308b\u80fd\u529b\u306b\u57fa\u3065\u3044\u3066\u3001\u56de\u8def\u8a2d\u8a08\u3092\u6b63\u5f53\u5316\u3057\u307e\u3059\u3002</p> <p>\u79c1\u305f\u3061\u306f\u3001Google\u306e\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30b5\u30fc\u30d3\u30b9\u3092\u4ecb\u3057\u3066\u30a2\u30af\u30bb\u30b9\u3057\u305fGoogle\u306eSycamore\u30d7\u30ed\u30bb\u30c3\u30b5\u4e0a\u3067\u3053\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002\u3053\u306e\u30de\u30b7\u30f3\u306f\u3001\u91cf\u5b50\u512a\u4f4d\u30c7\u30e2\u30f3\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u306eSycamore\u30c1\u30c3\u30d7[1]\u306b\u4f3c\u3066\u3044\u307e\u3059\u304c\u3001\u30a2\u30af\u30c6\u30a3\u30d6\u306a\u91cf\u5b50\u30d3\u30c3\u30c8\u306f23\u500b\u306e\u307f\u3067\u3059\u3002\u79c1\u305f\u3061\u306f\u3001\u975e\u81ea\u660e\u306a\u30af\u30e9\u30b7\u30ab\u30eb\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u7af6\u4e89\u529b\u306e\u3042\u308b\u7d50\u679c\u3092\u9054\u6210\u3057\u3001\u4e2d\u7a0b\u5ea6\u306e\u56de\u8def\u306e\u6b63\u78ba\u3055\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u8208\u5473\u6df1\u3044\u5206\u985e\u5668\u306e\u9811\u5065\u6027\u3092\u898b\u3064\u3051\u307e\u3059\u3002\u79c1\u305f\u3061\u306e\u7d50\u679c\u306f\u3001\u30ce\u30a4\u30ba\u306e\u3042\u308b\u30ab\u30fc\u30cd\u30eb\u6cd5\u3068\u73fe\u5b9f\u306e\u9ad8\u6b21\u5143\u30c7\u30fc\u30bf\u4e0a\u3067\u306e\u8ffd\u52a0\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u524d\u51e6\u7406\u3084\u6b21\u5143\u524a\u6e1b\u306a\u3057\u306b\u64cd\u4f5c\u3059\u308b\u305f\u3081\u306e\u6280\u8853\u306b\u95a2\u3059\u308b\u3055\u3089\u306a\u308b\u7406\u8ad6\u7684\u7814\u7a76\u3092\u4fc3\u3059\u3082\u306e\u3067\u3059\u3002</p> <p>[4]  \u672c\u6587:   reduction.</p> <p>\\section{Quantum kernel Support Vector Machines} </p> <p>A common task in machine learning is \\textit{supervised learning}, wherein an algorithm consumes datum-label pairs $(x, y) \\in \\mathcal{X} \\times {0, 1}$ and outputs a function $f: \\mathcal{X} \\rightarrow {0, 1}$ that ideally predicts labels for seen (training) input data and generalizes well to unseen (test) data. A popular supervised learning algorithm is the Support Vector Machine (SVM) \\cite{cortes1995support,Boser:1992:TAO:130385.130401} which is trained on inner products $\\langle x_i, x_j\\rangle$ in the input space to find a robust linear classification boundary that best separates the data. An important technique for generalizing SVM classifiers to non-linearly separable data is the so-called ``kernel trick''  which  \u548c\u8a33:  \\section{\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3}</p> <p>\u6a5f\u68b0\u5b66\u7fd2\u306e\u4e00\u822c\u7684\u306a\u30bf\u30b9\u30af\u306f\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u30c7\u30fc\u30bf-\u30e9\u30d9\u30eb\u306e\u30da\u30a2$(x, y) \\in \\mathcal{X} \\times {0, 1}$\u3092\u53d7\u3051\u53d6\u308a\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\u3057\u3001\u672a\u77e5\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3082\u3046\u307e\u304f\u6c4e\u5316\u3059\u308b\u95a2\u6570$f: \\mathcal{X} \\rightarrow {0, 1}$\u3092\u51fa\u529b\u3059\u308b\u300c\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u300d\u3067\u3059\u3002 \u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\uff08SVM\uff09\\cite{cortes1995support,Boser:1992:TAO:130385.130401}\u306f\u4eba\u6c17\u306e\u3042\u308b\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3042\u308a\u3001\u5165\u529b\u7a7a\u9593\u5185\u306e\u5185\u7a4d$\\langle x_i, x_j\\rangle$\u306b\u57fa\u3065\u3044\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u3001\u30c7\u30fc\u30bf\u3092\u6700\u3082\u3088\u304f\u5206\u96e2\u3059\u308b\u9811\u5065\u306a\u7dda\u5f62\u5206\u985e\u5883\u754c\u3092\u898b\u3064\u3051\u307e\u3059\u3002\u975e\u7dda\u5f62\u5206\u96e2\u53ef\u80fd\u306a\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066SVM\u5206\u985e\u5668\u3092\u4e00\u822c\u5316\u3059\u308b\u305f\u3081\u306e\u91cd\u8981\u306a\u624b\u6cd5\u306f\u3001\u300c\u30ab\u30fc\u30cd\u30eb\u30c8\u30ea\u30c3\u30af\u300d\u3068\u547c\u3070\u308c\u308b\u3082\u306e\u3067\u3059\u3002</p> <p>[5]  \u672c\u6587:   replaces  $\\langle x_i, x_j\\rangle$ in the SVM formulation by a symmetric positive definite kernel function $k(x_i, x_j)$ \\cite{Aizerman1964}. Since every kernel function corresponds to an inner product on input data mapped into a feature Hilbert space \\cite{aronszajn1950theory}, linear classification boundaries found by an SVM trained on a high-dimensional mapping correspond to complex, non-linear functions in the input space.  \\onecolumngrid</p> <p>\\begin{figure}[t]     \\centering     \\includegraphics[width=0.91\\textwidth]{plots/svm_flowchart.pdf}     \\caption{In this experiment we performed limited data preprocessing that is standard for state-of-the-art classical techniques, before using the quantum processor to estimate the kernel matrix $\\hat{K}_{ij}$ for all pairs of encoded datapoints $  \u548c\u8a33:  \\onecolumn</p> <p>[6]  \u672c\u6587:  (x_i, x_j)$ in each dataset. We then passed the kernel matrix back to a classical computer to optimize an SVM using cross validation and hyperparameter tuning before evaluating the SVM to produce a final train/test score.}     \\label{fig:svm_flowchart}</p> <p>\\end{figure}</p> <p>\\twocolumngrid Quantum kernel methods can potentially improve the performance of classifiers by using a quantum computer to map input data in $\\mathcal{X}\\subset \\mathbb{R}^d$ into a high-dimensional complex Hilbert space, potentially resulting in a kernel function that is expressive and  challenging to compute classically. It is difficult to know without sophisticated knowledge of the data generation process whether a given kernel is particularly suited to a dataset, but perhaps families of classically hard kernels may be sho  \u548c\u8a33:  \u56f3\\ref{fig:svm_flowchart}\u306b\u306f\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u306b\u3088\u3063\u3066\u5206\u985e\u5668\u306e\u6027\u80fd\u3092\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u5165\u529b\u30c7\u30fc\u30bf\u3092\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3001$\\mathbb{R}^d$\u306e\u9ad8\u6b21\u5143\u8907\u7d20\u30d2\u30eb\u30d9\u30eb\u30c8\u7a7a\u9593\u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b\u3053\u3068\u3067\u3001\u53e4\u5178\u7684\u306b\u8a08\u7b97\u3059\u308b\u306e\u304c\u56f0\u96e3\u306a\u30ab\u30fc\u30cd\u30eb\u95a2\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u305f\u3081\u3067\u3059\u3002\u4e0e\u3048\u3089\u308c\u305f\u30ab\u30fc\u30cd\u30eb\u304c\u7279\u5b9a\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u9069\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u306f\u3001\u30c7\u30fc\u30bf\u751f\u6210\u30d7\u30ed\u30bb\u30b9\u306e\u9ad8\u5ea6\u306a\u77e5\u8b58\u304c\u306a\u3051\u308c\u3070\u7406\u89e3\u3059\u308b\u306e\u306f\u96e3\u3057\u3044\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u304c\u3001\u304a\u305d\u3089\u304f\u53e4\u5178\u7684\u306b\u96e3\u89e3\u306a\u30ab\u30fc\u30cd\u30eb\u306e\u30d5\u30a1\u30df\u30ea\u30fc\u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u9069\u3057\u3066\u3044\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002</p> <p>[7]  \u672c\u6587:  wn empirically to offer performance improvements. In this work we focus on a non-variational quantum kernel method, which uses a quantum circuit $U(x)$ to map real data into quantum state space according to a map $\\phi(x) = U (x) |0\\rangle$. The  kernel function we employ is then the squared inner product between pairs of mapped input data given by  $k(x_i, x_j) = |\\langle \\phi(x_i) | \\phi(x_j) \\rangle|^2$, which allows for more expressive models compared to the alternative choice $\\langle \\phi (x_i) | \\phi (x_j) \\rangle$ \\cite{huang2020power}.</p> <p>In the absence of noise, the kernel matrix $K_{ij} = k(x_i, x_j)$ for a fixed dataset can therefore be estimated up to statistical error by using a quantum computer to sample outputs of the circuit $U^\\dagger (x_i) U (x_j)$ and then computing the e  \u548c\u8a33:  \u3053\u306e\u7814\u7a76\u3067\u306f\u3001\u5b9f\u30c7\u30fc\u30bf\u3092\u91cf\u5b50\u72b6\u614b\u7a7a\u9593\u306b\u5199\u50cf\u3059\u308b\u305f\u3081\u306b\u91cf\u5b50\u56de\u8def$U(x)$\u3092\u4f7f\u7528\u3059\u308b\u975e\u5909\u5206\u7684\u306a\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u306b\u7126\u70b9\u3092\u5f53\u3066\u307e\u3059\u3002\u5199\u50cf$\\phi(x) = U(x)|0\\rangle$\u306b\u5f93\u3063\u3066\u3001\u30de\u30c3\u30d7\u3055\u308c\u305f\u5165\u529b\u30c7\u30fc\u30bf\u306e\u30da\u30a2\u306e\u5185\u7a4d\u306e\u4e8c\u4e57\u3067\u3042\u308b\u30ab\u30fc\u30cd\u30eb\u95a2\u6570$k(x_i, x_j) = |\\langle\\phi(x_i) | \\phi(x_j)\\rangle|^2$\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u3053\u308c\u306b\u3088\u3063\u3066\u3001$\\langle\\phi(x_i) | \\phi(x_j)\\rangle$\u3068\u6bd4\u8f03\u3057\u3066\u3088\u308a\u8868\u73fe\u529b\u306e\u3042\u308b\u30e2\u30c7\u30eb\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\\cite{huang2020power}\u3002</p> <p>\u30ce\u30a4\u30ba\u306e\u306a\u3044\u5834\u5408\u3001\u56fa\u5b9a\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u3057\u3066\u30ab\u30fc\u30cd\u30eb\u884c\u5217$K_{ij} = k(x_i, x_j)$\u306f\u3001\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u56de\u8def$U^\\dagger(x_i)U(x_j)$\u306e\u51fa\u529b\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3001\u305d\u306e\u5f8c\u7d71\u8a08\u7684\u306a\u8aa4\u5dee\u3092\u8003\u616e\u3057\u3066\u63a8\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <p>[8]  \u672c\u6587:  mpirical probability of the all-zeros bitstring. However in practice, the kernel matrix $\\hat{K}{ij}$ sampled from the quantum computer may be significantly different from $K{ij}$ due to device noise and readout error. Once $\\hat{K}{ij}$ is computed for all pairs of input data in the training set, a classical SVM can be trained on the outputs of the quantum computer. An SVM trained on a size-$m$ training set $\\mathcal{T} \\subset \\mathcal{X}$ learns to predict the class $f(x) = \\hat{y}$ of an input data point $x$ according to the decision function: \\begin{equation}\\label{eq:decision_main} f(x) = \\text{sign}\\left(\\sum{i=1}^m \\alpha_{i} y_i k(x_i, x) + b\\right) \\end{equation} where $\\alpha_i$ and $b$ are parameters determined during the training stage of the SVM. Training and evaluating t  \u548c\u8a33:  \u5b9f\u8df5\u3067\u306f\u3001\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30ab\u30fc\u30cd\u30eb\u884c\u5217$\\hat{K}{ij}$\u306f\u3001\u30c7\u30d0\u30a4\u30b9\u306e\u30ce\u30a4\u30ba\u3084\u8aad\u307f\u53d6\u308a\u30a8\u30e9\u30fc\u306b\u3088\u308a$K{ij}$\u3068\u5927\u5e45\u306b\u7570\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002\u8a13\u7df4\u30bb\u30c3\u30c8\u306e\u3059\u3079\u3066\u306e\u5165\u529b\u30c7\u30fc\u30bf\u306e\u30da\u30a2\u306b\u5bfe\u3057\u3066$\\hat{K}{ij}$\u304c\u8a08\u7b97\u3055\u308c\u305f\u3089\u3001\u53e4\u5178SVM\u3092\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u306e\u51fa\u529b\u306b\u5bfe\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30b5\u30a4\u30ba-$m$\u306e\u8a13\u7df4\u30bb\u30c3\u30c8$\\mathcal{T} \\subset \\mathcal{X}$\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305fSVM\u306f\u3001\u6c7a\u5b9a\u95a2\u6570\u306b\u5f93\u3063\u3066\u5165\u529b\u30c7\u30fc\u30bf\u70b9$x$\u306e\u30af\u30e9\u30b9$f(x) = \\hat{y}$\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u3092\u5b66\u7fd2\u3057\u307e\u3059\uff1a $$ f(x) = \\text{sign}\\left(\\sum{i=1}^m \\alpha_{i} y_i k(x_i, x) + b\\right) $$ \u3053\u3053\u3067\u3001$\\alpha_i$\u3068$b$\u306fSVM\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u6bb5\u968e\u3067\u6c7a\u5b9a\u3055\u308c\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u3059\u3002\u8a13\u7df4\u3068\u8a55\u4fa1</p> <p>[9]  \u672c\u6587:  he SVM on $\\mathcal{T}$ requires an $m \\times m$ kernel matrix, after which each data point $z$ in the testing set $\\mathcal{V}\\subset \\mathcal{X}$ may be classified using an additional $m$ evaluations of $k(x_i, z)$ for $i=1\\dots m$. Figure \\ref{fig:svm_flowchart} provides a schematic representation of the process used to train an SVM using quantum kernels. </p> <p>% % % Preprocessing data \\subsection{Data and preprocessing} \\label{sec:dataset}</p> <p>We used the dataset provided in the Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC) \\cite{team2018photometric} that simulates observations of the Vera C. Rubin Observatory \\cite{verarubin}. The PLAsTiCC data consists of simulated astronomical time series for several different classes of astronomical objects. The time series  \u548c\u8a33:  SVM\u306e$\\mathcal{T}$\u4e0a\u3067\u306e\u5b9f\u88c5\u3067\u306f\u3001$m \\times m$\u306e\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u304c\u5fc5\u8981\u3067\u3042\u308a\u3001\u305d\u306e\u5f8c\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8$\\mathcal{V}\\subset \\mathcal{X}$\u5185\u306e\u5404\u30c7\u30fc\u30bf\u70b9$z$\u306f\u3001$i=1\\dots m$\u306b\u5bfe\u3057\u3066$k(x_i, z)$\u3092\u8a55\u4fa1\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5206\u985e\u3055\u308c\u308b\u3002\u56f3\\ref{fig:svm_flowchart}\u306b\u306f\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u3092\u4f7f\u7528\u3057\u3066SVM\u3092\u8a13\u7df4\u3059\u308b\u30d7\u30ed\u30bb\u30b9\u306e\u6982\u7565\u56f3\u304c\u793a\u3055\u308c\u3066\u3044\u308b\u3002</p> <p>\\subsection{\u30c7\u30fc\u30bf\u3068\u524d\u51e6\u7406} \\label{sec:dataset}</p> <p>\u79c1\u305f\u3061\u306f\u3001Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC)\u3067\u63d0\u4f9b\u3055\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\\cite{team2018photometric}\u3092\u4f7f\u7528\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u306f\u3001Vera C. Rubin Observatory\\cite{verarubin}\u306e\u89b3\u6e2c\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3057\u305f\u3082\u306e\u3067\u3001\u3044\u304f\u3064\u304b\u306e\u7570\u306a\u308b\u5929\u4f53\u30af\u30e9\u30b9\u306e\u305f\u3081\u306e\u6a21\u64ec\u5929\u4f53\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u304b\u3089\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <p>[10]  \u672c\u6587:   consist of measurements of flux at six wavelength bands. Here we work on data from the training set of the challenge. To transform the problem into a binary classification problem, we focus on the two most represented classes, 42 and 90, which correspond to types II and Ia supernovae, respectively.</p> <p>Each time series can have a different number of flux measurements in each of the six wavelength bands. In order to classify different time series using an algorithm with a fixed number of inputs, we transform each time series into the same set of derived quantities. These include: the number of measurements; the minimum, maximum, mean, median, standard deviation, and skew of both flux and flux error; the sum and skew of the ratio between flux and flux error, and of the flux times squared flux   \u548c\u8a33:  \u4ee5\u4e0b\u306f\u8ad6\u6587\u306eTeX\u306e\u6587\u7ae0\u306e\u548c\u8a33\u3067\u3059\u3002</p> <p>\u516d\u3064\u306e\u6ce2\u9577\u5e2f\u3067\u306e\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u6e2c\u5b9a\u304b\u3089\u306a\u308b\u30c7\u30fc\u30bf\u3067\u3059\u3002 \u3053\u3053\u3067\u306f\u3001\u30c1\u30e3\u30ec\u30f3\u30b8\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u306e\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 \u554f\u984c\u3092\u4e8c\u5024\u5206\u985e\u554f\u984c\u306b\u5909\u63db\u3059\u308b\u305f\u3081\u306b\u3001\u6700\u3082\u4ee3\u8868\u7684\u306a\u4e8c\u3064\u306e\u30af\u30e9\u30b9\u300142\u306890\u306b\u7126\u70b9\u3092\u5f53\u3066\u307e\u3059\u3002\u3053\u308c\u3089\u306f\u305d\u308c\u305e\u308cII\u578b\u3068Ia\u578b\u306e\u8d85\u65b0\u661f\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u5404\u6642\u7cfb\u5217\u306f\u3001\u516d\u3064\u306e\u6ce2\u9577\u5e2f\u3054\u3068\u306b\u7570\u306a\u308b\u6570\u306e\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u6e2c\u5b9a\u5024\u3092\u6301\u3064\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002 \u4e00\u5b9a\u306e\u5165\u529b\u6570\u3092\u6301\u3064\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u7528\u3057\u3066\u7570\u306a\u308b\u6642\u7cfb\u5217\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306b\u3001\u5404\u6642\u7cfb\u5217\u3092\u540c\u3058\u6d3e\u751f\u91cf\u306e\u30bb\u30c3\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002 \u3053\u308c\u306b\u306f\u3001\u6e2c\u5b9a\u56de\u6570\u3001\u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u30a8\u30e9\u30fc\u306e\u6700\u5c0f\u5024\u3001\u6700\u5927\u5024\u3001\u5e73\u5747\u5024\u3001\u4e2d\u592e\u5024\u3001\u6a19\u6e96\u504f\u5dee\u3001\u6b6a\u5ea6\u3001\u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u30a8\u30e9\u30fc\u306e\u6bd4\u7387\u306e\u5408\u8a08\u3068\u6b6a\u5ea6\u3001\u304a\u3088\u3073\u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u4e8c\u4e57\u306e\u7a4d\u306e\u5408\u8a08\u3068\u6b6a\u5ea6\u304c\u542b\u307e\u308c\u307e\u3059\u3002</p> <p>\u4ee5\u4e0b\u306f\u6821\u6b63\u3092\u3057\u305f\u5f8c\u3001Markdown\u5f62\u5f0f\u3067\u548c\u8a33\u3057\u305f\u6587\u7ae0\u3067\u3059\u3002</p> <p>\u4ee5\u4e0b\u306f\u8ad6\u6587\u306eTeX\u306e\u6587\u7ae0\u306e\u548c\u8a33\u3067\u3059\u3002</p> <p>6\u3064\u306e\u6ce2\u9577\u5e2f\u3067\u306e\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u6e2c\u5b9a\u304b\u3089\u6210\u308b\u30c7\u30fc\u30bf\u306b\u53d6\u308a\u7d44\u3093\u3067\u3044\u307e\u3059\u3002</p> <p>\u3053\u306e\u554f\u984c\u3092\uff12\u5024\u5206\u985e\u554f\u984c\u306b\u5909\u63db\u3059\u308b\u305f\u3081\u306b\u3001\u6700\u3082\u51fa\u73fe\u983b\u5ea6\u306e\u9ad8\u3044\uff12\u3064\u306e\u30af\u30e9\u30b9\u300142\u306890\uff08\u305d\u308c\u305e\u308cII\u578b\u3068Ia\u578b\u306e\u8d85\u65b0\u661f\u306b\u5bfe\u5fdc\uff09\u306b\u7126\u70b9\u3092\u5f53\u3066\u3066\u3044\u307e\u3059\u3002</p> <p>\u5404\u6642\u7cfb\u5217\u306f\u3001\uff16\u3064\u306e\u6ce2\u9577\u5e2f\u3054\u3068\u306b\u7570\u306a\u308b\u6570\u306e\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u6e2c\u5b9a\u5024\u3092\u6301\u3064\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>\u4e00\u5b9a\u306e\u5165\u529b\u6570\u3092\u6301\u3064\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u7528\u3057\u3066\u7570\u306a\u308b\u6642\u7cfb\u5217\u3092\u5206\u985e\u3059\u308b\u305f\u3081\u306b\u3001\u5404\u6642\u7cfb\u5217\u3092\u540c\u3058\u6d3e\u751f\u91cf\u306e\u30bb\u30c3\u30c8\u306b\u5909\u63db\u3057\u307e\u3059\u3002</p> <p>\u3053\u308c\u306b\u306f\u3001\u4ee5\u4e0b\u304c\u542b\u307e\u308c\u307e\u3059\uff1a - \u6e2c\u5b9a\u56de\u6570 - \u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u30a8\u30e9\u30fc\u306e\u6700\u5c0f\u5024\u3001\u6700\u5927\u5024\u3001\u5e73\u5747\u5024\u3001\u4e2d\u592e\u5024\u3001\u6a19\u6e96\u504f\u5dee\u3001\u6b6a\u5ea6 - \u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u30a8\u30e9\u30fc\u306e\u6bd4\u7387\u306e\u5408\u8a08\u3068\u6b6a\u5ea6 - \u30d5\u30e9\u30c3\u30af\u30b9\u3068\u30d5\u30e9\u30c3\u30af\u30b9\u306e\u4e8c\u4e57\u306e\u7a4d\u306e\u5408\u8a08\u3068\u6b6a\u5ea6</p> <p>[11]  \u672c\u6587:  ratio; the mean and maximum time between measurements; spectroscopic and photometric redshifts for the host galaxy; the position of each object in the sky; and the first two Fourier coefficients for each band, as well as kurtosis and skewness. In total, this transformation yields a 67-dimensional vector for each object.</p> <p>To prepare data for the quantum circuit, we convert lognormal-distributed spectral inputs to $\\log$ scale, and normalize all inputs to $\\left[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\right]$. We perform no dimensionality reduction. Our data processing pipeline is consistent with the treatment applied to state-of-the-art classical methods. Our classical benchmark is a competitive solution to this problem, although significant additional feature engineering leveraging astrophysics doma  \u548c\u8a33:  in knowledge has been performed. We obtain data from the Sloan Digital Sky Survey (SDSS), which provides spectroscopic and photometric redshift measurements for a large number of galaxies. For our task, we select objects that have both spectroscopic and photometric redshifts available. We randomly split the dataset into a training set containing 70% of the objects and a test set containing the remaining 30%.</p> <p>For the quantum circuit, we use the Qiskit library and the Aqua package for quantum machine learning. We construct a variational quantum circuit with trainable parameters, consisting of layers of single-qubit rotations followed by two-qubit entangling gates. The circuit is optimized by minimizing a cost function using a classical optimizer. The optimization is performed using a stochastic gradient descent algorithm, with a learning rate of 0.1.</p> <p>To evaluate the performance of our quantum model, we compare it to the classical benchmark on the test set. We use two evaluation metrics: the mean absolute error (MAE) and the root mean squared error (RMSE). The results show that our quantum model outperforms the classical benchmark, achieving lower MAE and RMSE values.</p> <p>In conclusion, we have successfully applied a variational quantum circuit to the problem of estimating redshifts for galaxies. Our quantum model outperforms the classical benchmark, demonstrating the potential of quantum machine learning in astrophysics. Further research is needed to explore the full capabilities of quantum machine learning in this field.</p> <p>[12]  \u672c\u6587:  in knowledge could possibly raise the benchmark score by a few percent.</p> <p>% % % Designing the circuit \\subsection{Circuit design}</p> <p>\\begin{figure}[htbp!]     \\centering     \\includegraphics[width=\\columnwidth]{plots/circuit_type2_structure.pdf}     \\caption{\\textbf{a.} 14-qubit example of the type 2 circuit used for experiments in this work. The dashed box indicates $U(x_i)$, while the remainder of the circuit computes $U^\\dagger(x_j)$ to ouput $|\\langle \\phi(x_j)|\\phi(x_i)\\rangle |^2$. Non-virtual gates occurring at the boundary (dashed line) are contracted for hardware runs. \\textbf{b.} The basic encoding block consists of a Hadamard followed by three single-qubit rotations, each parameterized by a different element of the input data $x$ (normalization and encoding constants omitted here).  \u548c\u8a33:  \\subsection{\u56de\u8def\u8a2d\u8a08}</p> <p>\\begin{figure}[htbp!]     \\centering     \\includegraphics[width=\\columnwidth]{plots/circuit_type2_structure.pdf}     \\caption{\\textbf{a.} \u3053\u306e\u7814\u7a76\u3067\u5b9f\u9a13\u306b\u4f7f\u7528\u3055\u308c\u305f\u30bf\u30a4\u30d72\u56de\u8def\u306e14\u91cf\u5b50\u30d3\u30c3\u30c8\u306e\u4f8b\u3002\u70b9\u7dda\u306e\u30dc\u30c3\u30af\u30b9\u306f$U(x_i)$\u3092\u793a\u3057\u3001\u6b8b\u308a\u306e\u56de\u8def\u306f$U^\\dagger(x_j)$\u3092\u8a08\u7b97\u3057\u3066$|\\langle \\phi(x_j)|\\phi(x_i)\\rangle |^2$\u3092\u51fa\u529b\u3057\u307e\u3059\u3002\u5883\u754c\uff08\u70b9\u7dda\uff09\u3067\u767a\u751f\u3059\u308b\u975e\u4eee\u60f3\u30b2\u30fc\u30c8\u306f\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u5b9f\u884c\u306e\u305f\u3081\u306b\u7e2e\u7d04\u3055\u308c\u307e\u3059\u3002\\textbf{b.} \u57fa\u672c\u306e\u30a8\u30f3\u30b3\u30fc\u30c9\u30d6\u30ed\u30c3\u30af\u306f\u3001Hadamard\u306b\u7d9a\u3044\u30663\u3064\u306e\u7570\u306a\u308b\u5165\u529b\u30c7\u30fc\u30bf$x$\u306e\u8981\u7d20\u3067\u30d1\u30e9\u30e1\u30fc\u30bf\u5316\u3055\u308c\u305f\u5358\u4e00\u91cf\u5b50\u30d3\u30c3\u30c8\u306e\u56de\u8ee2\u3067\u69cb\u6210\u3055\u308c\u307e\u3059\uff08\u3053\u3053\u3067\u306f\u6b63\u898f\u5316\u3068\u30a8\u30f3\u30b3\u30fc\u30c9\u5b9a\u6570\u306f\u7701\u7565\u3055\u308c\u3066\u3044\u307e\u3059\uff09\u3002} \\end{figure}</p> <p>[13]  \u672c\u6587:   \\textbf{c.} We used the $\\sqrt{\\text{iSWAP}}$ entangling gate, a hardware-native two-qubit gate on the Sycamore processor.}     \\label{fig:circuit_main}</p> <p>\\end{figure}</p> <p>To compute the kernel matrix $K_{ij} \\equiv k(x_i, x_j)$ over the fixed dataset we must run $R$ repetitions of each circuit $U^\\dagger (x_j) U(x_i)$ to determine the total counts $\\nu_0$ of the all zeros bitstring, resulting in an estimator $\\hat{K}_{ij} = \\frac{\\nu_0}{R}$. This introduces a challenge since quantum kernels must also be sampled from hardware with low enough statistical uncertainty to recover a classifier with similar performance to noiseless conditions. Since the likelihood of large relative statistical error between $K$ and $\\hat{K}$ grows with decreasing magnitude of $\\hat{K}$ and decreasing $R$, the perf  \u548c\u8a33:  c. \u6211\u3005\u306f\u3001Sycamore\u30d7\u30ed\u30bb\u30c3\u30b5\u4e0a\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30cd\u30a4\u30c6\u30a3\u30d6\u306e2\u91cf\u5b50\u30d3\u30c3\u30c8\u30b2\u30fc\u30c8\u3067\u3042\u308b$\\sqrt{\\text{iSWAP}}$\u30a8\u30f3\u30bf\u30f3\u30b0\u30ea\u30f3\u30b0\u30b2\u30fc\u30c8\u3092\u4f7f\u7528\u3057\u307e\u3057\u305f\u3002</p> <p>\u56fa\u5b9a\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u4e0a\u3067\u30ab\u30fc\u30cd\u30eb\u884c\u5217$K_{ij} \\equiv k(x_i, x_j)$\u3092\u8a08\u7b97\u3059\u308b\u305f\u3081\u306b\u3001\u5404\u56de\u8def$U^\\dagger (x_j) U(x_i)$\u3092$R$\u56de\u306e\u53cd\u5fa9\u5b9f\u884c\u3057\u3066\u3001\u3059\u3079\u3066\u306e\u30bc\u30ed\u30d3\u30c3\u30c8\u30b9\u30c8\u30ea\u30f3\u30b0\u306e\u7dcf\u6570$\\nu_0$\u3092\u6c42\u3081\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u3053\u306e\u7d50\u679c\u3001\u63a8\u5b9a\u5024$\\hat{K}_{ij} = \\frac{\\nu_0}{R}$\u304c\u5f97\u3089\u308c\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u30ce\u30a4\u30ba\u306e\u306a\u3044\u72b6\u614b\u3068\u540c\u69d8\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6301\u3064\u5206\u985e\u5668\u3092\u5fa9\u5143\u3059\u308b\u305f\u3081\u306b\u3001\u4f4e\u3044\u7d71\u8a08\u7684\u4e0d\u78ba\u304b\u3055\u3067\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u305f\u3081\u3001\u8ab2\u984c\u3092\u5f15\u304d\u8d77\u3053\u3057\u307e\u3059\u3002$\\hat{K}$\u3068$\\hat{K}$\u306e\u9593\u306e\u76f8\u5bfe\u7d71\u8a08\u8aa4\u5dee\u304c\u5927\u304d\u3044\u3068\u3044\u3046\u53ef\u80fd\u6027\u306f\u3001$\\hat{K}$\u306e\u7d76\u5bfe\u5024\u304c\u5c0f\u3055\u304f\u306a\u308a\u3001$R$\u304c\u5c0f\u3055\u304f\u306a\u308b\u307b\u3069\u5897\u52a0\u3057\u307e\u3059\u3002</p> <p>[14]  \u672c\u6587:  ormance of the hardware-based classifier will degrade when the kernel matrix to be sampled is populated by small entries. Conversely, large kernel magnitudes are a desirable feature for a successful quantum kernel classifier, and a key goal in circuit design is to balance the requirement of large kernel matrix elements with a choice of mapping that is difficult to compute classically. Another significant design challenge is to construct a circuit that separates data according to class without mapping data so far apart as to lose information about class relationships - an effect sometimes referred to as the ``curse of dimensionality'' in classical machine learning. </p> <p>For this experiment, we accounted for these design challenges and the need to accommodate high-dimensional data by mapping da  \u548c\u8a33:  \u6027\u80fd\u306e\u6e2c\u5b9a\u306f\u3001\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u304c\u5c0f\u3055\u3044\u30a8\u30f3\u30c8\u30ea\u3067\u4f5c\u6210\u3055\u308c\u305f\u5834\u5408\u3001\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30d9\u30fc\u30b9\u306e\u5206\u985e\u5668\u306e\u6027\u80fd\u304c\u4f4e\u4e0b\u3059\u308b\u3053\u3068\u304c\u3042\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\u9006\u306b\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u5206\u985e\u5668\u306e\u6210\u529f\u306b\u306f\u5927\u304d\u306a\u30ab\u30fc\u30cd\u30eb\u306e\u5024\u304c\u5fc5\u8981\u3067\u3042\u308a\u3001\u56de\u8def\u8a2d\u8a08\u306e\u4e3b\u306a\u76ee\u6a19\u306f\u3001\u5927\u304d\u306a\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u8981\u7d20\u306e\u8981\u4ef6\u3068\u3001\u53e4\u5178\u7684\u306b\u306f\u96e3\u3057\u3044\u30de\u30c3\u30d4\u30f3\u30b0\u306e\u9078\u629e\u3068\u306e\u30d0\u30e9\u30f3\u30b9\u3092\u53d6\u308b\u3053\u3068\u3067\u3059\u3002\u307e\u305f\u3001\u30af\u30e9\u30b9\u306b\u57fa\u3065\u3044\u3066\u30c7\u30fc\u30bf\u3092\u5206\u96e2\u3059\u308b\u56de\u8def\u3092\u69cb\u7bc9\u3059\u308b\u3068\u3044\u3046\u5225\u306e\u91cd\u8981\u306a\u8a2d\u8a08\u4e0a\u306e\u8ab2\u984c\u306f\u3001\u30af\u30e9\u30b9\u306e\u95a2\u4fc2\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u5931\u308f\u305a\u306b\u30c7\u30fc\u30bf\u3092\u3042\u307e\u308a\u9060\u304f\u306b\u30de\u30c3\u30d4\u30f3\u30b0\u3057\u306a\u3044\u3053\u3068\u3067\u3059-\u3053\u308c\u306f\u53e4\u5178\u7684\u306a\u6a5f\u68b0\u5b66\u7fd2\u3067\u306f\u300c\u6b21\u5143\u306e\u546a\u3044\u300d\u3068\u3082\u547c\u3070\u308c\u307e\u3059\u3002</p> <p>\u3053\u306e\u5b9f\u9a13\u3067\u306f\u3001\u3053\u308c\u3089\u306e\u8a2d\u8a08\u4e0a\u306e\u8ab2\u984c\u3068\u9ad8\u6b21\u5143\u30c7\u30fc\u30bf\u3078\u306e\u9069\u5fdc\u306e\u5fc5\u8981\u6027\u3092\u8003\u616e\u3057\u3001\u30c7\u30fc\u30bf\u3092\u30de\u30c3\u30d4\u30f3\u30b0\u3059\u308b\u3053\u3068\u3067\u3053\u308c\u3089\u306e\u8981\u4ef6\u3092\u6e80\u305f\u3059\u3053\u3068\u3068\u3057\u307e\u3057\u305f\u3002</p> <p>[15]  \u672c\u6587:  ta into quantum state space using the quantum circuit shown in Figure \\ref{fig:circuit_main}. Each local rotation in the circuit is parameterized by a single element of preprocessed input data so that inner products in the quantum state space correspond to a similarity measure for features in the input space. Importantly, the circuit structure is constrained by matching the input data dimensionality to the number of local rotations so that the circuit depth and qubit count individually do not significantly impact the performance of the SVM classifier in a noiseless setting. This circuit structure consistently results in large magnitude inner products (median $K \\geq 10^{\\text{-}1}$) resulting in estimates for $\\hat{K}$ with very little statistical error. We provide further empirical eviden  \u548c\u8a33:  ta\u3092\u91cf\u5b50\u72b6\u614b\u7a7a\u9593\u306b\u5909\u63db\u3059\u308b\u305f\u3081\u306b\u3001\u56f3\\ref{fig:circuit_main}\u306b\u793a\u3055\u308c\u305f\u91cf\u5b50\u56de\u8def\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\u56de\u8def\u5185\u306e\u5404\u5c40\u6240\u56de\u8ee2\u306f\u3001\u524d\u51e6\u7406\u3055\u308c\u305f\u5165\u529b\u30c7\u30fc\u30bf\u306e\u5358\u4e00\u306e\u8981\u7d20\u306b\u3088\u3063\u3066\u30d1\u30e9\u30e1\u30fc\u30bf\u5316\u3055\u308c\u3066\u304a\u308a\u3001\u91cf\u5b50\u72b6\u614b\u7a7a\u9593\u3067\u306e\u5185\u7a4d\u306f\u5165\u529b\u7a7a\u9593\u306e\u7279\u5fb4\u306e\u985e\u4f3c\u6027\u5c3a\u5ea6\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002\u91cd\u8981\u306a\u3053\u3068\u306b\u3001\u56de\u8def\u306e\u69cb\u9020\u306f\u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3092\u5c40\u6240\u56de\u8ee2\u306e\u6570\u3068\u4e00\u81f4\u3055\u305b\u308b\u3053\u3068\u3067\u5236\u7d04\u3055\u308c\u3066\u304a\u308a\u3001\u30ce\u30a4\u30ba\u306e\u306a\u3044\u72b6\u6cc1\u3067\u306f\u56de\u8def\u306e\u6df1\u3055\u3084\u30ad\u30e5\u30d3\u30c3\u30c8\u6570\u304cSVM\u5206\u985e\u5668\u306e\u6027\u80fd\u306b\u307b\u3068\u3093\u3069\u5f71\u97ff\u3092\u4e0e\u3048\u307e\u305b\u3093\u3002\u3053\u306e\u56de\u8def\u69cb\u9020\u306f\u4e00\u8cab\u3057\u3066\u5927\u304d\u306a\u5185\u7a4d\u306e\u5024\uff08\u4e2d\u592e\u5024$K \\geq 10^{\\text{-}1}$\uff09\u3092\u3082\u305f\u3089\u3057\u3001$\\hat{K}$\u306e\u63a8\u5b9a\u5024\u306b\u306f\u307b\u3068\u3093\u3069\u7d71\u8a08\u7684\u306a\u8aa4\u5dee\u304c\u3042\u308a\u307e\u305b\u3093\u3002\u307e\u305f\u3001\u3055\u3089\u306a\u308b\u7d4c\u9a13\u7684\u306a\u8a3c\u62e0\u3092\u63d0\u4f9b\u3057\u307e\u3059\u3002</p> <p>[16]  \u672c\u6587:  ce justifying our choice of circuit in Appendix \\ref{app:circuit}.</p> <p>%% Hardware and optimizations \\section{Hardware classification results}</p> <p>\\subsection{Dataset selection}\\label{sec:data_selection}</p> <p>\\begin{figure}     \\centering     \\includegraphics[width=\\columnwidth]{plots/learning_curve.pdf}     \\caption{Learning curve for an SVM trained using noiseless circuit encoding on 17 qubits  vs. RBF kernel $k(x_i, x_j) = \\exp(-\\gamma ||x_i - x_j ||^2)$.  Points reflect train/test accuracy for a classifier trained on a stratified 10-fold split resulting in a size-$x$ balanced subset of preprocessed supernova datapoints. Error bars indicate standard deviation over 10 trials of downsampling, and the dashed line indicates the size $m=210$ of the training set chosen for this experiment. % DON'T DELETE: % ci  \u548c\u8a33:  \\section{\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u5206\u985e\u7d50\u679c}</p> <p>\\subsection{\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u9078\u629e}\\label{sec:data_selection}</p> <p>\\begin{figure}     \\centering     \\includegraphics[width=\\columnwidth]{plots/learning_curve.pdf}     \\caption{17\u91cf\u5b50\u30d3\u30c3\u30c8\u3067\u30ce\u30a4\u30ba\u306e\u306a\u3044\u56de\u8def\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3092\u4f7f\u7528\u3057\u3066\u8a13\u7df4\u3055\u308c\u305fSVM\u306e\u5b66\u7fd2\u66f2\u7dda vs. RBF\u30ab\u30fc\u30cd\u30eb $k(x_i, x_j) = \\exp(-\\gamma ||x_i - x_j ||^2)$\u3002\u70b9\u306f\u3001\u524d\u51e6\u7406\u3055\u308c\u305f\u8d85\u65b0\u661f\u306e\u30c7\u30fc\u30bf\u30dd\u30a4\u30f3\u30c8\u306e\u30b5\u30f3\u30d7\u30eb\u30b5\u30a4\u30ba-$x$\u306e\u30d0\u30e9\u30f3\u30b9\u306e\u3068\u308c\u305f\u30b5\u30d6\u30bb\u30c3\u30c8\u306b\u3064\u3044\u3066\u3001\u5c64\u5225\u306e10\u5206\u5272\u3067\u8a13\u7df4\u3055\u308c\u305f\u5206\u985e\u5668\u306e\u8a13\u7df4/\u30c6\u30b9\u30c8\u7cbe\u5ea6\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\u30a8\u30e9\u30fc\u30d0\u30fc\u306f10\u56de\u306e\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306e\u6a19\u6e96\u504f\u5dee\u3092\u793a\u3057\u3001\u7834\u7dda\u306f\u3053\u306e\u5b9f\u9a13\u3067\u9078\u629e\u3055\u308c\u305f\u8a13\u7df4\u30bb\u30c3\u30c8\u306e\u30b5\u30a4\u30ba$m=210$\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002 % DON'T DELETE: % ci</p> <p>[17]  \u672c\u6587:  rcuit params: with hyperparameters $c_1=0.25$, $C=4$ % with $\\gamma=0.012$, $C=2.0$ optimized over a fine gridsearch on $\\gamma \\in [10^{\\text{-} 5}, 10^{\\text{-} 1}]$, $C\\in [1, 10^3]$.     }     \\label{fig:learning_curve} \\end{figure}</p> <p>We are motivated to minimize the size  $\\mathcal{T}\\subset\\mathcal{X}$ since the complexity cost of training an SVM on $m$ datapoints scales as $\\mathcal{O}(m^2)$. However too small a training sample will result in poor generalization of the trained model, resulting in low quality class predictions for data in the reserved size-$v$ test set $\\mathcal{V}$. We explored this tradeoff by simulating the classifiers for varying train set sizes in Cirq \\cite{Cirq} to construct learning curves (Figure \\ref{fig:learning_curve}) standard in machine learning. We found tha  \u548c\u8a33:  \u79c1\u305f\u3061\u306f\u3001$\\mathcal{X}$\u306e\u90e8\u5206\u96c6\u5408\u3067\u3042\u308b\u30b5\u30a4\u30ba$\\mathcal{T}$\u3092\u6700\u5c0f\u5316\u3059\u308b\u3053\u3068\u306b\u52d5\u6a5f\u3065\u3051\u3089\u308c\u3066\u3044\u307e\u3059\u3002\u306a\u305c\u306a\u3089\u3001$m$\u500b\u306e\u30c7\u30fc\u30bf\u30dd\u30a4\u30f3\u30c8\u3067SVM\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u969b\u306e\u8907\u96d1\u3055\u306e\u30b3\u30b9\u30c8\u306f$\\mathcal{O}(m^2)$\u3067\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u308b\u304b\u3089\u3067\u3059\u3002\u305f\u3060\u3057\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b5\u30f3\u30d7\u30eb\u30b5\u30a4\u30ba\u304c\u5c0f\u3055\u3059\u304e\u308b\u3068\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306e\u4e00\u822c\u5316\u304c\u60aa\u5316\u3057\u3001\u4e88\u7d04\u30b5\u30a4\u30ba-$v$\u306e\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8$\\mathcal{V}$\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u30af\u30e9\u30b9\u306e\u4e88\u6e2c\u306e\u54c1\u8cea\u304c\u4f4e\u4e0b\u3057\u307e\u3059\u3002\u3053\u306e\u30c8\u30ec\u30fc\u30c9\u30aa\u30d5\u3092\u8abf\u67fb\u3059\u308b\u305f\u3081\u306b\u3001Cirq \\cite{Cirq}\u3067\u7570\u306a\u308b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30bb\u30c3\u30c8\u30b5\u30a4\u30ba\u306b\u5bfe\u3059\u308b\u5206\u985e\u5668\u3092\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3057\u3001\u6a5f\u68b0\u5b66\u7fd2\u3067\u6a19\u6e96\u7684\u306a\u5b66\u7fd2\u66f2\u7dda\uff08\u56f3\\ref{fig:learning_curve}\uff09\u3092\u69cb\u7bc9\u3057\u307e\u3057\u305f\u3002\u6211\u3005\u306f\u4ee5\u4e0b\u306e\u3053\u3068\u3092\u898b\u3064\u3051\u307e\u3057\u305f\u3002</p> <p>[18]  \u672c\u6587:  t our simulated 17-qubit classifier applied to 67-dimensional supernova data was competitive compared to a classical SVM trained using the Radial Basis Function (RBF) kernel on identical data subsets. For hardware runs, we constructed train/test datasets for which the mean train and k-fold validation scores achieved approximately the mean performance over randomly downsampled data subsets, accounting for the SVM hyperparameter optimization. The final dataset for each choice of qubits was constructed by producing a $1000 \\times 1000$ simulated kernel matrix , repeatedly performing 4-fold cross validation on a size-280 subset, and then selecting as the train/test set the exact elements from the fold that resulted in an accuracy closest to the mean validation score over all trials and folds.   \u548c\u8a33:  \u79c1\u305f\u3061\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f17\u30ad\u30e5\u30fc\u30d3\u30c3\u30c8\u306e\u5206\u985e\u5668\u306f\u300167\u6b21\u5143\u306e\u8d85\u65b0\u661f\u30c7\u30fc\u30bf\u306b\u9069\u7528\u3057\u305f\u5834\u5408\u3001\u540c\u3058\u30c7\u30fc\u30bf\u306e\u90e8\u5206\u96c6\u5408\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u653e\u5c04\u57fa\u5e95\u95a2\u6570(RBF)\u30ab\u30fc\u30cd\u30eb\u3092\u4f7f\u7528\u3057\u305f\u53e4\u5178\u7684\u306aSVM\u3068\u7af6\u4e89\u529b\u304c\u3042\u308a\u307e\u3057\u305f\u3002\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30e9\u30f3\u306e\u5834\u5408\u3001SVM\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6700\u9069\u5316\u3092\u8003\u616e\u3057\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u90e8\u5206\u96c6\u5408\u306e\u5e73\u5747\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u8fd1\u3044\u5e73\u5747\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30b3\u30a2\u3068k-fold\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30b9\u30b3\u30a2\u3092\u5b9f\u73fe\u3059\u308b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3057\u305f\u3002\u5404\u30ad\u30e5\u30d3\u30c3\u30c8\u306e\u9078\u629e\u3054\u3068\u306b\u6700\u7d42\u7684\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3001$1000 \\times 1000$\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u3092\u751f\u6210\u3057\u3001\u30b5\u30a4\u30ba280\u306e\u90e8\u5206\u96c6\u5408\u30674\u3064\u6298\u308a\u306e\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u884c\u3057\u3001\u8a66\u884c\u3054\u3068\u306e\u3059\u3079\u3066\u306e\u30d5\u30a9\u30fc\u30eb\u30c9\u306b\u308f\u305f\u308b\u5e73\u5747\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30b9\u30b3\u30a2\u306b\u6700\u3082\u8fd1\u3044\u7cbe\u5ea6\u3092\u793a\u3059\u30d5\u30a9\u30fc\u30eb\u30c9\u306e\u8981\u7d20\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u3068\u3057\u3066\u9078\u629e\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u69cb\u7bc9\u3055\u308c\u307e\u3057\u305f\u3002</p> <p>\u79c1\u305f\u3061\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f17\u30ad\u30e5\u30fc\u30d3\u30c3\u30c8\u306e\u5206\u985e\u5668\u306f\u300167\u6b21\u5143\u306e\u8d85\u65b0\u661f\u30c7\u30fc\u30bf\u306b\u9069\u7528\u3057\u305f\u5834\u5408\u3001\u540c\u3058\u30c7\u30fc\u30bf\u306e\u90e8\u5206\u96c6\u5408\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u653e\u5c04\u57fa\u5e95\u95a2\u6570(RBF)\u30ab\u30fc\u30cd\u30eb\u3092\u4f7f\u7528\u3057\u305f\u53e4\u5178\u7684\u306aSVM\u3068\u7af6\u4e89\u529b\u304c\u3042\u308a\u307e\u3057\u305f\u3002 \u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30e9\u30f3\u306e\u5834\u5408\u3001SVM\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6700\u9069\u5316\u3092\u8003\u616e\u3057\u3001\u30e9\u30f3\u30c0\u30e0\u306b\u30c0\u30a6\u30f3\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u90e8\u5206\u96c6\u5408\u306e\u5e73\u5747\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u8fd1\u3044\u5e73\u5747\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30b3\u30a2\u3068k-fold\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30b9\u30b3\u30a2\u3092\u5b9f\u73fe\u3059\u308b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3057\u307e\u3057\u305f\u3002 \u5404\u30ad\u30e5\u30d3\u30c3\u30c8\u306e\u9078\u629e\u3054\u3068\u306b\u6700\u7d42\u7684\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3001$1000 \\times 1000$\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30c8\u3055\u308c\u305f\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u3092\u751f\u6210\u3057\u3001\u30b5\u30a4\u30ba280\u306e\u90e8\u5206\u96c6\u5408\u30674\u3064\u6298\u308a\u306e\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u884c\u3057\u3001\u8a66\u884c\u3054\u3068\u306e\u3059\u3079\u3066\u306e\u30d5\u30a9\u30fc\u30eb\u30c9\u306b\u308f\u305f\u308b\u5e73\u5747\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u30b9\u30b3\u30a2\u306b\u6700\u3082\u8fd1\u3044\u7cbe\u5ea6\u3092\u793a\u3059\u30d5\u30a9\u30fc\u30eb\u30c9\u306e\u8981\u7d20\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u3068\u3057\u3066\u9078\u629e\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u69cb\u7bc9\u3055\u308c\u307e\u3057\u305f\u3002 </p> <p>[19]  \u672c\u6587: </p> <p>%% Postprocessing, hyperparameter tuning \\subsection{Hardware classification and Postprocessing}\\label{sec:main_svm}</p> <p>\\begin{figure}[!htbp]</p> <pre><code>\\centering\n\\includegraphics[width=\\columnwidth]{plots/hw_acc_results_combined_v4.pdf}\n\\caption{\\textbf{a.} Parameters for the three circuits implemented in this experiment. Values in parentheses are calculated ignoring contributions due to virtual Z gates. \\textbf{b.} The depth of the each circuit and number of entangling layers (dark grey) scales to accommodate all 67 features of the input data, so that the expressive power of the circuit doesn't change significantly across different numbers of qubits. \\textbf{c.} The test accuracy for hardware QKM is competitive with the noiseless simulations even in the case of relatively low circuit fi&lt;br/&gt;\n</code></pre> <p>\u548c\u8a33:  \\subsection{\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u5206\u985e\u3068\u5f8c\u51e6\u7406}\\label{sec:main_svm}</p> <p>\\begin{figure}[!htbp]</p> <pre><code>\\centering\n\\includegraphics[width=\\columnwidth]{plots/hw_acc_results_combined_v4.pdf}\n\\caption{\\textbf{a.} \u3053\u306e\u5b9f\u9a13\u3067\u5b9f\u88c5\u3055\u308c\u305f3\u3064\u306e\u56de\u8def\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3002\u62ec\u5f27\u5185\u306e\u5024\u306f\u4eee\u60f3Z\u30b2\u30fc\u30c8\u306e\u5bc4\u4e0e\u3092\u7121\u8996\u3057\u3066\u8a08\u7b97\u3055\u308c\u308b\u3002\\textbf{b.} \u5404\u56de\u8def\u306e\u6df1\u3055\u3068\u30a8\u30f3\u30bf\u30f3\u30b0\u30eb\u30ec\u30a4\u30e4\u30fc\u306e\u6570\uff08\u6fc3\u3044\u7070\u8272\uff09\u306f\u3001\u5168\u3066\u306e67\u306e\u7279\u5fb4\u91cf\u3092\u53ce\u5bb9\u3059\u308b\u305f\u3081\u306b\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3055\u308c\u3066\u304a\u308a\u3001\u56de\u8def\u306e\u8868\u73fe\u80fd\u529b\u306f\u7570\u306a\u308b\u91cf\u5b50\u30d3\u30c3\u30c8\u306e\u6570\u306b\u5bfe\u3057\u3066\u5927\u304d\u304f\u5909\u5316\u3059\u308b\u3053\u3068\u306f\u306a\u3044\u3002\\textbf{c.} \u30cf\u30fc\u30c9\u30a6\u30a7\u30a2QKM\u306e\u30c6\u30b9\u30c8\u7cbe\u5ea6\u306f\u3001\u6bd4\u8f03\u7684\u4f4e\u3044\u56de\u8def\u306e\u6df1\u3055\u306e\u5834\u5408\u3067\u3082\u30ce\u30a4\u30ba\u306e\u306a\u3044\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u7af6\u4e89\u529b\u304c\u3042\u308b\u3002&lt;br/&gt;&lt;br/&gt;\n</code></pre> <p>[20]  \u672c\u6587:  delity, across multiple choices of qubit counts. The presence of hardware noise significantly reduces the ability of the model to overfit the data. Error bars on simulated data represent standard deviation of accuracy for an ensemble of SVM classifiers trained on 10 size-$m$ downsampled kernel matrices and tested on size-$v$ downsampled test sets (no replacement). Dataset sampling errors are propagated to the hardware outcomes but lack of larger hardware training/test sets prevents appropriate characterization of of a similar margin of error.}     \\label{fig:hero1}      % \\label{fig:kernel_and_circuits} \\end{figure}</p> <p>We computed the quantum kernels experimentally using the Google Sycamore processor \\cite{Arute2019} accessed through Google's Quantum Computing Service. At the time of experimen  \u548c\u8a33:  \u305f\u3001Google\u306e\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u30b5\u30fc\u30d3\u30b9\u3092\u901a\u3058\u3066\u30a2\u30af\u30bb\u30b9\u3055\u308c\u305fGoogle Sycamore\u30d7\u30ed\u30bb\u30c3\u30b5\\cite{Arute2019}\u3092\u4f7f\u7528\u3057\u3066\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u3092\u5b9f\u9a13\u7684\u306b\u8a08\u7b97\u3057\u307e\u3057\u305f\u3002\u5b9f\u9a13\u6642\u306b\u306f\u3001\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308bqubit\u6570\u306b\u5236\u7d04\u304c\u3042\u308a\u307e\u3057\u305f\u3002\u79c1\u305f\u3061\u306f\u3001\u7570\u306a\u308bqubit\u6570\u306e\u5834\u5408\u306e\u5b9f\u9a13\u7d50\u679c\u306e\u4e00\u8cab\u6027\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306b\u3001\u8907\u6570\u306equbit\u6570\u306e\u5834\u5408\u306b\u3064\u3044\u3066\u3082\u540c\u69d8\u306e\u5b9f\u9a13\u3092\u884c\u3044\u307e\u3057\u305f\u3002\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30ce\u30a4\u30ba\u306e\u5b58\u5728\u306f\u3001\u30e2\u30c7\u30eb\u304c\u30c7\u30fc\u30bf\u306b\u30aa\u30fc\u30d0\u30fc\u30d5\u30a3\u30c3\u30c8\u3059\u308b\u80fd\u529b\u3092\u5927\u5e45\u306b\u4f4e\u4e0b\u3055\u305b\u307e\u3059\u3002\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u306e\u30a8\u30e9\u30fc\u30d0\u30fc\u306f\u300110\u30b5\u30a4\u30ba\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6e08\u307f\u30ab\u30fc\u30cd\u30eb\u884c\u5217\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u3001\u30b5\u30a4\u30ba-v\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6e08\u307f\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\uff08\u7f6e\u63db\u306a\u3057\uff09\u3067\u30c6\u30b9\u30c8\u3055\u308c\u305fSVM\u5206\u985e\u5668\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u306e\u7cbe\u5ea6\u306e\u6a19\u6e96\u504f\u5dee\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u30a8\u30e9\u30fc\u306f\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u7d50\u679c\u306b\u4f1d\u64ad\u3055\u308c\u307e\u3059\u304c\u3001\u3088\u308a\u5927\u304d\u306a\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u306e\u4e0d\u8db3\u306f\u3001\u540c\u69d8\u306e\u8aa4\u5dee\u306e\u7bc4\u56f2\u3092\u9069\u5207\u306b\u7279\u5fb4\u4ed8\u3051\u308b\u3053\u3068\u3092\u59a8\u3052\u3066\u3044\u307e\u3059\u3002</p> <p>[21]  \u672c\u6587:  ts, the device consisted of 23 superconducting qubits with nearest neighbor (grid) connectivity. The processor supports single-qubit Pauli gates with $&gt;99\\%$ randomized benchmarking fidelity and $\\sqrt{i\\text{SWAP}}$ native entangling gates with XEB fidelities \\cite{Neill195,Arute2019} typically greater than $97\\%$.</p> <p>To test our classifier performance on hardware, we trained a quantum kernel SVM using $n$ qubit circuits for $n\\in{10, 14, 17}$ on $d=67$ supernova data with balanced class priors using a $m=210, v=70$ train/test split. We ran 5000 repetitions per circuit for a total of $m(m-1)/2 + mv \\approx 1.83 \\times 10^8$ experiments per number of qubits. As described in Section \\ref{sec:data_selection}, the train and test sets were constructed to provide a faithful representation of cl  \u548c\u8a33:  \u4ee5\u4e0b\u306eTeX\u306e\u6587\u7ae0\u3092\u548c\u8a33\u3057\u307e\u3059\u3002</p> <p>\u30c6\u30ad\u30b9\u30c8\u306e\u6587\u7ae0: ts, the device consisted of 23 superconducting qubits with nearest neighbor (grid) connectivity. The processor supports single-qubit Pauli gates with $&gt;99\\%$ randomized benchmarking fidelity and $\\sqrt{i\\text{SWAP}}$ native entangling gates with XEB fidelities \\cite{Neill195,Arute2019} typically greater than $97\\%$.</p> <p>To test our classifier performance on hardware, we trained a quantum kernel SVM using $n$ qubit circuits for $n\\in{10, 14, 17}$ on $d=67$ supernova data with balanced class priors using a $m=210, v=70$ train/test split. We ran 5000 repetitions per circuit for a total of $m(m-1)/2 + mv \\approx 1.83 \\times 10^8$ experiments per number of qubits. As described in Section \\ref{sec:data_selection}, the train and test sets were constructed to provide a faithful representation of cl.</p> <p>\u548c\u8a33\u5f8c\u306e\u6587\u7ae0:</p> <p>\u3053\u306e\u30c7\u30d0\u30a4\u30b9\u306f\u3001\u6700\u3082\u8fd1\u3044\u96a3\u63a5\uff08\u30b0\u30ea\u30c3\u30c9\uff09\u63a5\u7d9a\u3092\u6301\u306423\u500b\u306e\u8d85\u4f1d\u5c0e\u30ad\u30e5\u30d3\u30c3\u30c8\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u3053\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u306f\u3001$&gt;99\\%$\u306e\u30e9\u30f3\u30c0\u30e0\u30d9\u30f3\u30c1\u30de\u30fc\u30ad\u30f3\u30b0\u306e\u4fe1\u983c\u6027\u3092\u6301\u3064\u5358\u4e00\u30ad\u30e5\u30d3\u30c3\u30c8\u30dd\u30fc\u30ea\u30b2\u30fc\u30c8\u3068\u3001XEB\u306e\u4fe1\u983c\u6027\\cite{Neill195,Arute2019}\u304c\u901a\u5e38$97\\%$\u4ee5\u4e0a\u306e$\\sqrt{i\\text{SWAP}}$\u30cd\u30a4\u30c6\u30a3\u30d6\u30a8\u30f3\u30bf\u30f3\u30b0\u30eb\u30b2\u30fc\u30c8\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u4e0a\u3067\u5206\u985e\u5668\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u30c6\u30b9\u30c8\u3059\u308b\u305f\u3081\u306b\u3001\u79c1\u305f\u3061\u306f$n\\in{10, 14, 17}$\u306e$n$\u30ad\u30e5\u30d3\u30c3\u30c8\u56de\u8def\u3092\u4f7f\u7528\u3057\u3066\u91cf\u5b50\u30ab\u30fc\u30cd\u30ebSVM\u3092\u8a13\u7df4\u3057\u307e\u3057\u305f\u3002\u8a13\u7df4\u304a\u3088\u3073\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u306f\u3001$d=67$\u306e\u8d85\u65b0\u661f\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3001\u30af\u30e9\u30b9\u306e\u4e8b\u524d\u78ba\u7387\u304c\u30d0\u30e9\u30f3\u30b9\u3055\u308c\u305f\u72b6\u614b\u3068\u306a\u308b\u3088\u3046\u306b$m=210, v=70$\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0/\u30c6\u30b9\u30c8\u5206\u5272\u3092\u4f7f\u7528\u3057\u307e\u3057\u305f\u3002\u5404\u56de\u8def\u306b\u3064\u304d5000\u56de\u306e\u7e70\u308a\u8fd4\u3057\u3092\u884c\u3044\u3001\u30ad\u30e5\u30d3\u30c3\u30c8\u306e\u6570\u3054\u3068\u306b$m(m-1)/2 + mv \\approx 1.83 \\times 10^8$\u306e\u5b9f\u9a13\u3092\u5b9f\u65bd\u3057\u307e\u3057\u305f\u3002\u30bb\u30af\u30b7\u30e7\u30f3\\ref{sec:data_selection}\u3067\u8aac\u660e\u3057\u305f\u3088\u3046\u306b\u3001\u8a13\u7df4\u30bb\u30c3\u30c8\u3068\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u306f\u30af\u30e9\u30b9\u306e\u5fe0\u5b9f\u306a\u8868\u73fe\u3092\u63d0\u4f9b\u3059\u308b\u3088\u3046\u306b\u69cb\u7bc9\u3055\u308c\u307e\u3057\u305f\u3002 </p> <p>[22]  \u672c\u6587:  assifier accuracy applied to datasets of restricted size. Typically the time cost of computing the decision function (Equation \\ref{eq:decision_main}) is reduced to some fraction of $mv$ since only a small subset of training inputs are selected as support vectors. However in hardware experiments we observed that a large fraction ($&gt;90 \\%$) of data in $\\mathcal{T}$ were selected as support vectors, likely due to a combination of a complex decision boundary and noise in the calculation of $\\hat{K}$.</p> <p>Training the SVM classifier in postprocessing required choosing a single hyperparameter $C$ that applies a penalty for misclassification, which can significantly affect the noise robustness of the final classifier. To determine $C$ without overfitting the model, we performed leave-one-out cross   \u548c\u8a33:  \u5236\u9650\u3055\u308c\u305f\u30b5\u30a4\u30ba\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u9069\u7528\u3055\u308c\u308b\u5206\u985e\u5668\u306e\u7cbe\u5ea6\u3002\u901a\u5e38\u3001\u6c7a\u5b9a\u95a2\u6570\uff08\u65b9\u7a0b\u5f0f\\ref{eq:decision_main}\uff09\u306e\u8a08\u7b97\u306e\u6642\u9593\u30b3\u30b9\u30c8\u306f\u3001\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u3068\u3057\u3066\u9078\u629e\u3055\u308c\u308b\u8a13\u7df4\u5165\u529b\u306e\u4e00\u90e8\u306e\u307f\u304c\u8003\u616e\u3055\u308c\u308b\u305f\u3081\u3001$mv$\u306e\u4e00\u90e8\u306b\u524a\u6e1b\u3055\u308c\u307e\u3059\u3002\u3057\u304b\u3057\u3001\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u5b9f\u9a13\u3067\u306f\u3001$\\mathcal{T}$\u5185\u306e\u30c7\u30fc\u30bf\u306e\u5927\u90e8\u5206\uff08$&gt;90 %$\uff09\u304c\u8907\u96d1\u306a\u6c7a\u5b9a\u5883\u754c\u3068$\\hat{K}$\u306e\u8a08\u7b97\u306e\u30ce\u30a4\u30ba\u306e\u7d44\u307f\u5408\u308f\u305b\u306b\u3088\u308a\u3001\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u3068\u3057\u3066\u9078\u629e\u3055\u308c\u308b\u3053\u3068\u304c\u89b3\u5bdf\u3055\u308c\u307e\u3057\u305f\u3002</p> <p>\u5f8c\u51e6\u7406\u3067\u306eSVM\u5206\u985e\u5668\u306e\u8a13\u7df4\u306f\u3001\u8aa4\u5206\u985e\u306b\u5bfe\u3059\u308b\u30da\u30ca\u30eb\u30c6\u30a3\u3092\u9069\u7528\u3059\u308b\u5358\u4e00\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf$C$\u3092\u9078\u629e\u3059\u308b\u3053\u3068\u3092\u5fc5\u8981\u3068\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u306f\u3001\u6700\u7d42\u7684\u306a\u5206\u985e\u5668\u306e\u30ce\u30a4\u30ba\u306e\u5805\u7262\u6027\u306b\u5927\u304d\u306a\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\u30e2\u30c7\u30eb\u306e\u904e\u5b66\u7fd2\u3092\u305b\u305a\u306b$C$\u3092\u6c7a\u5b9a\u3059\u308b\u305f\u3081\u306b\u3001\u6211\u3005\u306f\u4e00\u3064\u629c\u304d\u4ea4\u5dee\u3092\u5b9f\u884c\u3057\u307e\u3057\u305f\u3002</p> <p>[23]  \u672c\u6587:  validation (LOOCV) on $\\mathcal{T}$ to determine $C_{opt}$ corresponding to the maximum mean LOOCV score. We then fixed $C=C_{opt}$ to evaluate the test accuracy $\\frac{1}{v}\\sum_{j=1}^v \\Pr( f(x_j)\\neq y_j)$ on reserved datapoints taken from $\\mathcal{V}$. Figure \\ref{fig:hero1} shows the classifier accuracies for each number of qubits, and demonstrates that the performance of the QKM is not restricted by the number of qubits used. Significantly, the QKM classifier performs reasonably well even when observed bitstring probabilities (and therefore $\\hat{K}_{ij}$) are suppressed by a factor of 50\\%-70\\% due to limited circuit fidelity. This is due in part to the fact that the SVM decision function is invariant under scaling transformations $K \\rightarrow r K$ and highlights the noise robust  \u548c\u8a33: </p> <p>$\\mathcal{T}$\u4e0a\u306e\u4e00\u3064\u629c\u304d\u4ea4\u5dee\u691c\u8a3c\uff08LOOCV\uff09\u3092\u884c\u3044\u3001\u6700\u5927\u306e\u5e73\u5747LOOCV\u30b9\u30b3\u30a2\u306b\u5bfe\u5fdc\u3059\u308b$C_{opt}$\u3092\u6c7a\u5b9a\u3057\u307e\u3059\u3002\u6b21\u306b\u3001$C=C_{opt}$\u3092\u56fa\u5b9a\u3057\u3066\u3001$\\mathcal{V}$\u304b\u3089\u53d6\u5f97\u3055\u308c\u305f\u4e88\u7d04\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30dd\u30a4\u30f3\u30c8\u4e0a\u3067\u306e\u30c6\u30b9\u30c8\u7cbe\u5ea6$\\frac{1}{v}\\sum_{j=1}^v \\Pr( f(x_j)\\neq y_j)$\u3092\u8a55\u4fa1\u3057\u307e\u3059\u3002\u56f3\\ref{fig:hero1}\u306f\u3001\u30ad\u30e5\u30d3\u30c3\u30c8\u6570\u3054\u3068\u306e\u5206\u985e\u5668\u306e\u7cbe\u5ea6\u3092\u793a\u3057\u3066\u304a\u308a\u3001QKM\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u4f7f\u7528\u3055\u308c\u308b\u30ad\u30e5\u30d3\u30c3\u30c8\u306e\u6570\u306b\u3088\u3063\u3066\u5236\u9650\u3055\u308c\u3066\u3044\u306a\u3044\u3053\u3068\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\u7279\u306b\u3001\u56de\u8def\u306e\u5fe0\u5b9f\u5ea6\u304c\u4f4e\u3044\u305f\u3081\u306b\u30d3\u30c3\u30c8\u6587\u5b57\u5217\u306e\u78ba\u7387\uff08\u305d\u3057\u3066\u3057\u305f\u304c\u3063\u3066$\\hat{K}_{ij}$\uff09\u304c50\uff05-70\uff05\u306e\u8981\u56e0\u3067\u6291\u5236\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u3067\u3082\u3001QKM\u5206\u985e\u5668\u306f\u304b\u306a\u308a\u3046\u307e\u304f\u6a5f\u80fd\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u3001SVM\u306e\u6c7a\u5b9a\u95a2\u6570\u304c\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u5909\u63db$K \\rightarrow r K$\u306e\u4e0b\u3067\u4e0d\u5909\u3067\u3042\u308b\u3068\u3044\u3046\u4e8b\u5b9f\u306b\u90e8\u5206\u7684\u306b\u8d77\u56e0\u3057\u3066\u304a\u308a\u3001\u30ce\u30a4\u30ba\u306b\u5bfe\u3059\u308b\u5805\u7262\u6027\u3092\u5f37\u8abf\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>[24]  \u672c\u6587:  ness of quantum kernel methods.</p> <p>\\section{Conclusion and outlook}</p> <p>Whether and how quantum computing will contribute to machine learning for real world classical datasets remains to be seen. In this work, we have demonstrated that quantum machine learning at an intermediate scale (10 to 17 qubits) can work on \u201cnatural\u201d datasets using Google\u2019s superconducting quantum computer. In particular, we presented a novel circuit ansatz capable of processing high-dimensional data from a real-world scientific experiment without dimensionality reduction or significant pre-processing on input data, and without the requirement that the number of qubits matches the data dimensionality. We demonstrated classification results that were competitive with noiseless simulation despite hardware noise and lack o  \u548c\u8a33:  \u89b3\u6e2c\u3055\u308c\u308b\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u306e\u52b9\u679c</p> <p>\\section{\u7d50\u8ad6\u3068\u5c55\u671b}</p> <p>\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0\u304c\u5b9f\u969b\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3044\u3066\u3001\u3069\u306e\u3088\u3046\u306b\u6a5f\u68b0\u5b66\u7fd2\u306b\u8ca2\u732e\u3059\u308b\u304b\u306f\u307e\u3060\u898b\u6975\u3081\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u672c\u7814\u7a76\u3067\u306f\u3001Google\u306e\u8d85\u4f1d\u5c0e\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3001\u4e2d\u7a0b\u5ea6\u306e\u898f\u6a21\uff0810\u301c17\u30ad\u30e5\u30fc\u30d3\u30c3\u30c8\uff09\u3067\u81ea\u7136\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5bfe\u5fdc\u3059\u308b\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u304c\u52d5\u4f5c\u3059\u308b\u3053\u3068\u3092\u793a\u3057\u307e\u3057\u305f\u3002\u7279\u306b\u3001\u6b21\u5143\u524a\u6e1b\u3084\u5165\u529b\u30c7\u30fc\u30bf\u3078\u306e\u5927\u5e45\u306a\u524d\u51e6\u7406\u306e\u306a\u3044\u3001\u5b9f\u4e16\u754c\u306e\u79d1\u5b66\u7684\u5b9f\u9a13\u304b\u3089\u306e\u9ad8\u6b21\u5143\u30c7\u30fc\u30bf\u3092\u51e6\u7406\u3067\u304d\u308b\u65b0\u3057\u3044\u56de\u8def\u30a2\u30f3\u30b5\u30c3\u30c4\u3092\u63d0\u793a\u3057\u307e\u3057\u305f\u3002\u307e\u305f\u3001\u91cf\u5b50\u30d3\u30c3\u30c8\u306e\u6570\u304c\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3068\u4e00\u81f4\u3059\u308b\u3053\u3068\u3092\u8981\u6c42\u3057\u306a\u3044\u3068\u3044\u3046\u70b9\u3082\u7279\u5fb4\u3067\u3059\u3002\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u306e\u30ce\u30a4\u30ba\u3084\u4e0d\u8db3\u306a\u3069\u306b\u3082\u304b\u304b\u308f\u3089\u305a\u3001\u30ce\u30a4\u30ba\u306e\u306a\u3044\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u7af6\u5408\u3059\u308b\u5206\u985e\u7d50\u679c\u3092\u793a\u3057\u307e\u3057\u305f\u3002</p> <p>[25]  \u672c\u6587:  f quantum error correction. While the circuits we implemented are not candidates for demonstrating quantum advantage, these findings suggest quantum kernel methods may be capable of achieving high classification accuracy on near-term devices. </p> <p>Careful attention must be paid to the impact of shot statistics and kernel element magnitudes when evaluating the performance of quantum kernel methods. This work highlights the need for further theoretical investigation under these constraints, as well as motivates further studies in the properties of noisy kernels. </p> <p>The main open problem is to identify a \u201cnatural\u201d data set that could lead to beyond-classical performance for quantum machine learning. We believe that this can be achieved on datasets that demonstrate correlations that are inherently  \u548c\u8a33:  \u6c42\u3081\u3089\u308c\u305f\u30c6\u30ad\u30b9\u30c8\u306e\u548c\u8a33\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059:</p> <p>\u91cf\u5b50\u8aa4\u308a\u8a02\u6b63\u306b\u304a\u3051\u308b\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u65b9\u6cd5\u306e\u5b9f\u88c5\u306f\u3001\u91cf\u5b50\u5229\u70b9\u3092\u793a\u3059\u5019\u88dc\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u3053\u308c\u3089\u306e\u7d50\u679c\u306f\u3001\u8fd1\u3044\u5c06\u6765\u306e\u30c7\u30d0\u30a4\u30b9\u3067\u3082\u9ad8\u3044\u5206\u985e\u7cbe\u5ea6\u3092\u9054\u6210\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3053\u3068\u3092\u793a\u5506\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u65b9\u6cd5\u306e\u6027\u80fd\u8a55\u4fa1\u306b\u304a\u3044\u3066\u3001\u30b7\u30e7\u30c3\u30c8\u7d71\u8a08\u3068\u30ab\u30fc\u30cd\u30eb\u8981\u7d20\u306e\u5927\u304d\u3055\u306e\u5f71\u97ff\u306b\u6ce8\u610f\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306e\u7814\u7a76\u306f\u3001\u3053\u308c\u3089\u306e\u5236\u7d04\u4e0b\u3067\u306e\u3055\u3089\u306a\u308b\u7406\u8ad6\u7684\u306a\u8abf\u67fb\u306e\u5fc5\u8981\u6027\u3092\u5f37\u8abf\u3057\u3001\u30ce\u30a4\u30ba\u306e\u3042\u308b\u30ab\u30fc\u30cd\u30eb\u306e\u7279\u6027\u306b\u95a2\u3059\u308b\u3055\u3089\u306a\u308b\u7814\u7a76\u3092\u4fc3\u3059\u3082\u306e\u3067\u3059\u3002</p> <p>\u6700\u3082\u91cd\u8981\u306a\u8ab2\u984c\u306f\u3001\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u306e\u30af\u30e9\u30b7\u30ab\u30eb\u3092\u8d85\u3048\u308b\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u3082\u305f\u3089\u3059\u53ef\u80fd\u6027\u304c\u3042\u308b\u300c\u81ea\u7136\u306a\u300d\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7279\u5b9a\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u79c1\u305f\u3061\u306f\u3001\u672c\u8cea\u7684\u306b\u76f8\u95a2\u3092\u793a\u3059\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u3053\u308c\u304c\u9054\u6210\u3067\u304d\u308b\u3068\u8003\u3048\u3066\u3044\u307e\u3059\u3002</p> <p>[26]  \u672c\u6587:   difficult to represent or store on a classical computer, hence inherently difficult or inefficient to learn/infer on a classical computer. This could include quantum data from simulations of quantum many-body systems near a critical point or solving linear and nonlinear systems of equations on a quantum computer \\cite{Kiani2020, lloyd2020quantum}. The quantum data could be also generated from quantum sensing and quantum communication applications. The software library TensorFlow Quantum (TFQ) \\cite{TFQ2020} was recently developed to facilitate the exploration of various combinations of data, models, and algorithms for quantum machine learning. Very recently, a quantum advantage has been proposed for some engineered dataset and numerically validated on up to 30 qubits in TFQ using similar   \u548c\u8a33:  \u53e4\u5178\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u3067\u306f\u8868\u73fe\u3084\u4fdd\u5b58\u304c\u56f0\u96e3\u306a\u91cf\u5b50\u30c7\u30fc\u30bf\u306f\u3001\u305d\u306e\u305f\u3081\u53e4\u5178\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u4e0a\u3067\u5b66\u7fd2/\u63a8\u8ad6\u3059\u308b\u3053\u3068\u306f\u56f0\u96e3\u3067\u3042\u308b\u304b\u975e\u52b9\u7387\u7684\u3067\u3042\u308b\u3068\u8a00\u3048\u308b\u3002\u3053\u308c\u306b\u306f\u3001\u81e8\u754c\u70b9\u4ed8\u8fd1\u306e\u91cf\u5b50\u591a\u4f53\u7cfb\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u5f97\u3089\u308c\u305f\u91cf\u5b50\u30c7\u30fc\u30bf\u3001\u307e\u305f\u306f\u91cf\u5b50\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u4e0a\u3067\u306e\u7dda\u5f62\u304a\u3088\u3073\u975e\u7dda\u5f62\u65b9\u7a0b\u5f0f\u306e\u89e3\u306a\u3069\u304c\u542b\u307e\u308c\u308b\u3053\u3068\u304c\u3042\u308b\\cite{Kiani2020, lloyd2020quantum}\u3002\u91cf\u5b50\u30c7\u30fc\u30bf\u306f\u3001\u91cf\u5b50\u30bb\u30f3\u30b7\u30f3\u30b0\u3084\u91cf\u5b50\u901a\u4fe1\u306e\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u3082\u751f\u6210\u3055\u308c\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u30e9\u30a4\u30d6\u30e9\u30eaTensorFlow Quantum (TFQ)\\cite{TFQ2020}\u306f\u3001\u3055\u307e\u3056\u307e\u306a\u30c7\u30fc\u30bf\u3001\u30e2\u30c7\u30eb\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u7d44\u307f\u5408\u308f\u305b\u3092\u63a2\u7d22\u3059\u308b\u305f\u3081\u306b\u6700\u8fd1\u958b\u767a\u3055\u308c\u307e\u3057\u305f\u3002\u6700\u8fd1\u3067\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u3064\u3044\u3066\u91cf\u5b50\u306e\u5229\u70b9\u304c\u63d0\u6848\u3055\u308c\u3001TFQ\u4e0a\u3067\u6700\u592730\u91cf\u5b50\u30d3\u30c3\u30c8\u307e\u3067\u6570\u5024\u7684\u306b\u691c\u8a3c\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p> <p>[27]  \u672c\u6587:  quantum kernel methods as described in this experimental demonstration \\cite{huang2020power}. These developments in quantum machine learning alongside the experimental results of this work suggest the exciting possibility for realizing quantum advantage with quantum machine learning on near term processors.   \u548c\u8a33:  \u3053\u306e\u5b9f\u9a13\u30c7\u30e2\u30f3\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u8aac\u660e\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u306b\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u306f\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u306e\u9032\u5c55\u3067\u3059\\cite{huang2020power}\u3002\u3053\u306e\u7814\u7a76\u306e\u5b9f\u9a13\u7d50\u679c\u3068\u3068\u3082\u306b\u3001\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u306b\u304a\u3051\u308b\u91cf\u5b50\u30a2\u30c9\u30d0\u30f3\u30c6\u30fc\u30b8\u306e\u5b9f\u73fe\u53ef\u80fd\u6027\u3092\u793a\u5506\u3057\u3066\u3044\u307e\u3059\u3002</p> <p>\u548c\u8a33\uff08\u6821\u6b63\u5f8c\u3001markdown\u5f62\u5f0f\uff09\uff1a</p> <p>\u3053\u306e\u5b9f\u9a13\u30c7\u30e2\u30f3\u30b9\u30c8\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u8aac\u660e\u3055\u308c\u3066\u3044\u308b\u3088\u3046\u306b\u3001\u91cf\u5b50\u30ab\u30fc\u30cd\u30eb\u6cd5\u306f\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u306e\u9032\u5c55\u3067\u3059 [@huang2020power]\u3002\u3053\u306e\u7814\u7a76\u306e\u5b9f\u9a13\u7d50\u679c\u3068\u5171\u306b\u3001\u8fd1\u3044\u5c06\u6765\u306e\u30d7\u30ed\u30bb\u30c3\u30b5\u4e0a\u3067\u306e\u91cf\u5b50\u6a5f\u68b0\u5b66\u7fd2\u306b\u3088\u308b\u91cf\u5b50\u30a2\u30c9\u30d0\u30f3\u30c6\u30fc\u30b8\u306e\u5b9f\u73fe\u53ef\u80fd\u6027\u304c\u793a\u5506\u3055\u308c\u3066\u3044\u307e\u3059\u3002</p>"}]}